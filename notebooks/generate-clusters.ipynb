{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AuroraAI](images/auroraai-small.png)\n",
    "\n",
    "\n",
    "# Cluster generation script \n",
    "\n",
    "This script performs clustering and factor analysis for a prepared dataset. It assumes three input files, with two of them being mandatory and one optional:\n",
    "\n",
    "* `METAFILE`: Metadata file in Excel format.\n",
    "* `VARSFILE`: Preprocessed actual data variables in CSV format\n",
    "* `BGRVFILE`: Preprocessed background variables in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import __version__\n",
    "from sklearn import decomposition, manifold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "except ImportError:\n",
    "    print('UMAP not available or fails to import, disabling it.')\n",
    "    umap = None\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from joblib import dump, load\n",
    "import json\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from yamlconfig import read_config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and define configuration settings\n",
    "\n",
    "Select the used dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read local settings from a YML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(verbose=True)\n",
    "assert DATASET in config, \"Selected dataset {} not found in config\"\n",
    "c = config[DATASET]\n",
    "print('Settings:')\n",
    "print(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default values for settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_KMEANS_MODEL, LOAD_FA_MODEL, LOAD_PCA_MODEL = None, None, None\n",
    "MODELDIR = None\n",
    "CSV_SEP = ','\n",
    "INDEX_COL = False # used to be None\n",
    "POINTSIZE = 5\n",
    "TRANSPOSE = False\n",
    "OUTDIR = \".\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply config values for settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATADIR = c['datadir']\n",
    "VARSFILE = c['varsfile']\n",
    "BGRVFILE = c['bgrvfile']\n",
    "METAFILE = c['metafile']\n",
    "if 'index_col' in c:\n",
    "    INDEX_COL = c['index_col']\n",
    "if 'n_clusters_kmeans' in c:\n",
    "    N_CLUSTERS_KMEANS = c['n_clusters_kmeans']\n",
    "if 'pointsize' in c:\n",
    "    POINTSIZE = c['pointsize']\n",
    "if 'transpose' in c:\n",
    "     TRANSPOSE = c['transpose']\n",
    "if 'outdir' in c:\n",
    "    OUTDIR = c['outdir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsfilename = \"{}/{}\".format(DATADIR, VARSFILE)\n",
    "metafilename = \"{}/{}\".format(DATADIR, METAFILE)\n",
    "bgrvfilename = \"{}/{}\".format(DATADIR, BGRVFILE)\n",
    "\n",
    "assert os.path.isfile(varsfilename), \"File missing\"\n",
    "assert os.path.isfile(metafilename), \"File missing\"\n",
    "assert os.path.isfile(bgrvfilename), \"File missing\"\n",
    "\n",
    "if not os.path.isdir(OUTDIR):\n",
    "    os.mkdir(OUTDIR)\n",
    "    print('Created directory', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def todaystr():\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vars = pd.read_excel(metafilename, index_col=0)\n",
    "df_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSPOSE:\n",
    "    df_vars = df_vars.transpose()\n",
    "    display(df_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimrows = []\n",
    "dimlist = []\n",
    "dims = {}\n",
    "varrow, shortdescrow, descriptionrow, backgroundrow, multiplierrow = None, None, None, None, None\n",
    "for i, idx in enumerate(df_vars.index):\n",
    "    if idx.lower().startswith(\"muuttuja\"):\n",
    "        varrow = i\n",
    "    if \"lyhyt kuvaus\" in idx.lower():\n",
    "        shortdescrow = i\n",
    "    elif \"kuvaus\" in idx.lower():\n",
    "        descriptionrow = i\n",
    "    if \"taustamuuttuja\" in idx.lower():\n",
    "        backgroundrow = i\n",
    "    if \"kerroin\" in idx.lower():\n",
    "        multiplierrow = i\n",
    "    if idx.startswith(\"DIM:\"):\n",
    "        dimrows.append(i)\n",
    "        parts = idx.split(\":\")\n",
    "        dimlist.append(parts[1])\n",
    "        dims[parts[1]] = {'order': len(dims), 'description': parts[2], 'columns': []}\n",
    "print(varrow, shortdescrow, descriptionrow, backgroundrow, multiplierrow)\n",
    "if shortdescrow is None:\n",
    "    shortdescrow = varrow\n",
    "if descriptionrow is None:\n",
    "    descriptionrow = varrow\n",
    "print(dims)\n",
    "print(dimlist)\n",
    "print(dimrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsdict = defaultdict()\n",
    "varslist = df_vars.columns\n",
    "for i_c, col in enumerate(varslist):\n",
    "    #print(col)\n",
    "    #print(df_vars[col].iloc[descriptionrow])\n",
    "    varsdict[col] = {'short_description': df_vars[col].iloc[shortdescrow],\n",
    "                     'description': df_vars[col].iloc[descriptionrow],\n",
    "                     'background': df_vars[col].iloc[backgroundrow]>0,\n",
    "                     'multiplier': df_vars[col].iloc[multiplierrow]}\n",
    "    dimindices = np.argwhere(df_vars[col].iloc[dimrows].fillna(0).values > 0)\n",
    "    dlist = []\n",
    "    for d in dimindices:\n",
    "        dlist.append(dimlist[d[0]])\n",
    "    varsdict[col]['dimensions'] = dlist\n",
    "    \n",
    "with open('{}/variables-{}.json'.format(OUTDIR, todaystr()), 'w', encoding='utf-8') as f:\n",
    "    json.dump(varsdict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(varsfilename, index_col=INDEX_COL)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_c, col in enumerate(df.columns):\n",
    "    assert col in varslist, col+\" not found in variable descriptions\"    \n",
    "    for d in varsdict[col]['dimensions']:\n",
    "        dims[d]['columns'].append(i_c)\n",
    "\n",
    "with open('{}/dimensions-{}.json'.format(OUTDIR, todaystr()), 'w', encoding='utf-8') as f:\n",
    "    json.dump(dims, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg = pd.read_csv(bgrvfilename, index_col=INDEX_COL)\n",
    "df_bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring data to numpy, run scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isnull().sum().sum()==0, \"NULLs exists!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means\n",
    "\n",
    "### Run k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_KMEANS_MODEL is None:\n",
    "    kmeans = KMeans(n_clusters=N_CLUSTERS_KMEANS)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    _fn = \"kmeans-{}.joblib\".format(todaystr())\n",
    "    dump(kmeans, \"{}/{}\".format(OUTDIR, _fn))\n",
    "    print('Wrote', _fn)\n",
    "else:\n",
    "    _fn = \"{}/{}\".format(MODELDIR, LOAD_KMEANS_MODEL)\n",
    "    assert os.path.isfile(_fn), \"File missing: \"+_fn\n",
    "    kmeans = load(_fn)\n",
    "    print('Loaded', LOAD_KMEANS_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = kmeans.labels_\n",
    "y = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run factor analysis\n",
    "\n",
    "This is already here although actual FA is done later, as 1st factor needed for sorting the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 4\n",
    "assert n_factors>3\n",
    "\n",
    "if LOAD_FA_MODEL is None:\n",
    "    fa = decomposition.FactorAnalysis(n_components=n_factors, random_state=42)\n",
    "    X_fa = fa.fit_transform(X)\n",
    "\n",
    "    _fn = \"fa-{}.joblib\".format(todaystr())\n",
    "    dump(fa, \"{}/{}\".format(OUTDIR, _fn))\n",
    "    print('Wrote', _fn)\n",
    "else:\n",
    "    _fn = \"{}/{}\".format(MODELDIR, LOAD_FA_MODEL)\n",
    "    assert os.path.isfile(_fn), \"File missing\"\n",
    "    fa = load(_fn)\n",
    "    print('Loaded', LOAD_FA_MODEL)\n",
    "    X_fa = fa.transform(X)\n",
    "\n",
    "orig_cc_fa = fa.transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = np.zeros(len(y), dtype=int)\n",
    "new_kmeans_cc=np.zeros(kmeans.cluster_centers_.shape)\n",
    "zipped = list(zip(range(8),list(orig_cc_fa[:,0])))\n",
    "sorted_clusters = sorted(zipped, key=lambda x: x[1])\n",
    "clusterdict = {}\n",
    "for i, c in enumerate(sorted_clusters):\n",
    "    clusterdict[c[0]] = i\n",
    "for i,v in enumerate(y):\n",
    "    new_y[i] = clusterdict[v]\n",
    "for i in range(new_kmeans_cc.shape[0]):\n",
    "    new_kmeans_cc[i,:]=kmeans.cluster_centers_[sorted_clusters[i][0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(N_CLUSTERS_KMEANS):\n",
    "    #plt.plot(kmeans.cluster_centers_[c,:]-np.mean(X, axis=0));\n",
    "    plt.plot(new_kmeans_cc[c,:]-np.mean(X, axis=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans_centers = pd.DataFrame(new_kmeans_cc, columns=df.columns)\n",
    "df_kmeans_centers.index = np.arange(1, len(df_kmeans_centers)+1)\n",
    "df_kmeans_centers.to_pickle(\"{}/kmeans_centers-{}.pkl\".format(OUTDIR, todaystr()))\n",
    "df_kmeans_centers.to_csv(\"{}/kmeans_centers-{}.csv\".format(OUTDIR, todaystr()), sep=\";\")\n",
    "df_kmeans_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print most significant variables for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_uniq, _counts = np.unique(new_y, return_counts=True)\n",
    "yc = dict(zip(_uniq, _counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(N_CLUSTERS_KMEANS):\n",
    "    #diff = kmeans.cluster_centers_[c,:] #-np.mean(X, axis=0)\n",
    "    diff = new_kmeans_cc[c,:] #-np.mean(X, axis=0)\n",
    "    absdiff = np.abs(diff)\n",
    "    #sorted = np.flip(np.sort(absdiff))\n",
    "    sorted_indices = np.flip(np.argsort(absdiff))\n",
    "    print('\\n### K-MEANS {} ({:.1f}%) ###'.format(c+1, 100*yc[c]/len(new_y)))\n",
    "    for i in range(10):\n",
    "        var = df.columns[sorted_indices[i]]\n",
    "        print(\"{:.2f} {} ({})\".format(diff[sorted_indices[i]],\n",
    "                                      var, varsdict[var]['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_labels = ['Klusteri '+str(c) for c in range(1,N_CLUSTERS_KMEANS+1)]\n",
    "kmeans_descriptions = ['Klusteri '+str(c) for c in range(1,N_CLUSTERS_KMEANS+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterwise means for both clustering and background variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfs_bg = [], []\n",
    "for c in range(N_CLUSTERS_KMEANS):\n",
    "    dfs.append(df.iloc[new_y==c].mean())\n",
    "    dfs_bg.append(df_bg.iloc[new_y==c].mean(numeric_only=True))\n",
    "df_means = pd.concat(dfs, axis=1).transpose()\n",
    "df_bg_means = pd.concat(dfs_bg, axis=1).transpose()\n",
    "\n",
    "df_means.to_pickle(\"{}/kmeans_muuttujat-{}.pkl\".format(OUTDIR, todaystr()))\n",
    "df_means.to_csv(\"{}/kmeans_muuttujat-{}.csv\".format(OUTDIR, todaystr()), sep=\";\")\n",
    "\n",
    "df_bg_means.to_pickle(\"{}/kmeans_taustamuuttujat-{}.pkl\".format(OUTDIR, todaystr()))\n",
    "df_bg_means.to_csv(\"{}/kmeans_taustamuuttujat-{}.csv\".format(OUTDIR, todaystr()), sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a Stiglitz dimension for all the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stigvals, stigstrip = [], []\n",
    "\n",
    "for d in dims.keys():\n",
    "    ndim = dims[d]['order']\n",
    "    stigvals.append([])\n",
    "    stigstrip.append([])\n",
    "    for c in range(N_CLUSTERS_KMEANS):\n",
    "        X_cluster = X[new_y==c]\n",
    "        n_vals, stigval = 0, 0.0\n",
    "        ssx, ssy, ssv = [], [], []\n",
    "        for dc in dims[d]['columns']:\n",
    "            dv = df.columns[dc]\n",
    "            val = X_cluster[:,dc].mean()*varsdict[dv]['multiplier']\n",
    "            ssx.append(ndim)\n",
    "            ssy.append(val)\n",
    "            ssv.append(dv)\n",
    "            #print(ssx, ssy)\n",
    "            stigval += val\n",
    "            n_vals += 1\n",
    "            #print(\"{}: {:.2f}\".format(sv, val))\n",
    "        \n",
    "        mean_stigval = 0.0\n",
    "        if n_vals>0:\n",
    "            mean_stigval = stigval/n_vals\n",
    "        stigvals[ndim].append(mean_stigval)\n",
    "        stigstrip[ndim].append((ssx,ssy,ssv))\n",
    "        #print(\"AVERAGE: {} {:.2f}\".format(c+1, stigval/n_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect variables for a certain Stiglitz and cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stigstrip[6][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dims.keys():\n",
    "    ndim = dims[d]['order']\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.gca()\n",
    "    colors=3*(np.array(stigvals[ndim])<0).astype(int)\n",
    "    sx, sy = [], []\n",
    "    for i, ss in enumerate(stigstrip[ndim]):\n",
    "        sx = sx + [i+1]*len(ss[1])\n",
    "        sy = sy + ss[1]\n",
    "    plt.bar(list(range(len(stigvals[ndim]))), stigvals[ndim], \n",
    "            color=[sns.color_palette()[c] for c in colors])\n",
    "    if len(sx):\n",
    "        sns.stripplot(x=sx, y=sy, size=8, color=sns.color_palette()[2], linewidth=1)\n",
    "    plt.plot([-1, N_CLUSTERS_KMEANS], [0,0])\n",
    "    plt.xlim([-0.5, N_CLUSTERS_KMEANS-0.5])\n",
    "    plt.ylim([-1.95, 1.95])\n",
    "    plt.title('\"{}\" eri klustereissa'.format(dims[d]['description']),\n",
    "              fontsize='large');\n",
    "    plt.savefig(\"{}/stiglitz2-{}.png\".format(OUTDIR, d), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all Stiglitz dimensions for a cluster\n",
    "\n",
    "#### Plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stigvecs = []\n",
    "for c in range(N_CLUSTERS_KMEANS):\n",
    "    stigvec = []\n",
    "    for ndim in range(len(dims)):\n",
    "        stigvec.append(stigvals[ndim][c])\n",
    "    stigvecs.append(stigvec)    \n",
    "    sx, sy = [], []\n",
    "    for i, ss in enumerate(stigstrip):\n",
    "        sx = sx + ss[c][0]\n",
    "        sy = sy + ss[c][1]\n",
    "        #print(ss[0][0])\n",
    "        #if c==0:\n",
    "            #print(ss[0][2])\n",
    "    if 1:\n",
    "        plt.figure(figsize=(16,5))\n",
    "        ax = plt.gca()\n",
    "        colors=3*(np.array(stigvec)<0).astype(int)\n",
    "        plt.bar(range(len(stigvec)), np.tanh(stigvec),\n",
    "            color=[sns.color_palette()[co] for co in colors])\n",
    "        sns.stripplot(x=sx, y=np.tanh(sy), size=8, color=sns.color_palette()[2], linewidth=1)\n",
    "        plt.plot([-1, len(dims)], [0,0])\n",
    "        plt.xticks(list(range(len(dims))), dims.keys(),\n",
    "                fontsize='small')\n",
    "        plt.xlim([-0.5, len(dims)-0.5])\n",
    "        plt.ylim([-1.05, 1.05])\n",
    "        plt.title('Stiglitz-ulottuvuudet klusterissa {}'.format(c+1), fontsize='x-large');\n",
    "        plt.savefig(\"{}/stiglitz-klusteri-{}.png\".format(OUTDIR, c+1), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dcl = pd.DataFrame(np.array(stigvecs), columns=dims.keys())\n",
    "df_dcl[\"klusteri\"] = range(1,N_CLUSTERS_KMEANS+1)\n",
    "df_dcl = df_dcl.set_index(\"klusteri\")\n",
    "prop = []\n",
    "for c in range(N_CLUSTERS_KMEANS):\n",
    "    prop.append(yc[c]/len(new_y))\n",
    "df_dcl[\"osuus\"] = prop\n",
    "df_dcl[\"koko\"] = [yc[c] for c in range(N_CLUSTERS_KMEANS)]\n",
    "\n",
    "df_dcl.to_csv(\"{}/klusterit-{}.csv\".format(OUTDIR, todaystr()))\n",
    "\n",
    "df_dcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/klusterimuuttujat2-{}.csv\".format(OUTDIR, todaystr()), 'w') as f:\n",
    "    f.write(\"klusteri;x;y;x_noise;variable\\n\")\n",
    "    for s in range(len(stigstrip)):\n",
    "        for i_c, c in enumerate(stigstrip[s]):\n",
    "            for l in range(len(c[0])):\n",
    "                f.write(\"{};{};{};{};{}\\n\".format(i_c+1, c[0][l], c[1][l],\n",
    "                                                  c[0][l]+np.random.normal(loc=0.0, scale=0.03),\n",
    "                                                  c[2][l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common plot functions\n",
    "\n",
    "These are common to FA, PCA, UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DEFAULT_COLORS = [\"#1B9E77\", \"#D95F02\", \"#7570B3\", \"#E7298A\", \"#66A61E\"]\n",
    "DEFAULT_COLORS = sns.color_palette(\"bright\")\n",
    "\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "def plot_embedding(X, CC=None, title=None, cov_ell=None,\n",
    "                   coloring=None, n_CC=None, palette=None, \n",
    "                   remove_nans=False, sizes=None, counts=None,\n",
    "                   save_as=None, xylabels=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    if CC is not None:\n",
    "        CC = (CC - x_min) / (x_max - x_min)\n",
    "    if n_CC is None:\n",
    "        n_CC = N_CLUSTERS_KMEANS\n",
    "    if coloring is None:\n",
    "        coloring = y\n",
    "    if remove_nans:\n",
    "        notnan = ~np.isnan(coloring)\n",
    "        X = X[notnan,:]\n",
    "        coloring = coloring[notnan]\n",
    "        if sizes is not None and not isinstance(sizes, (int, float)):\n",
    "            sizes = sizes[notnan]\n",
    "    if sizes is None:\n",
    "        sizes = 1.0\n",
    "    if palette is None:\n",
    "        colors = DEFAULT_COLORS\n",
    "    else:\n",
    "        colors = palette\n",
    "    \n",
    "    plt.figure(figsize=(18,10))\n",
    "    ax = plt.gca()\n",
    "    #plt.axis('off')\n",
    "    if xylabels is not None:\n",
    "        plt.xlabel(xylabels[0], fontsize='x-large', fontweight='bold')\n",
    "        plt.ylabel(xylabels[1], fontsize='x-large', fontweight='bold')\n",
    "    #ax.xaxis.set_visible(False)\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    ax.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    ax.patch.set_visible(False)\n",
    "    \n",
    "    #plt.scatter(X[:,0], X[:,1], s=sizes,\n",
    "    #            color=[plt.cm.Set1(int(yi) / 10.) for yi in coloring])\n",
    "    plt.scatter(X[:,0], X[:,1], s=sizes,\n",
    "                color=[colors[int(yi)] for yi in coloring])\n",
    "    if cov_ell is not None:\n",
    "        for i in range(n_CC):\n",
    "            XX = X[coloring==i]\n",
    "            confidence_ellipse(XX[:,0], XX[:,1], ax, n_std=cov_ell,\n",
    "                               edgecolor='k', lw=4)\n",
    "            confidence_ellipse(XX[:,0], XX[:,1], ax, n_std=cov_ell,\n",
    "                               edgecolor=colors[int(i)], lw=2)\n",
    "    if CC is not None:\n",
    "        clusters = range(n_CC)\n",
    "        plt.scatter(CC[:,0], CC[:,1], s=200.0, \n",
    "                    c=[colors[int(yi)] for yi in clusters],\n",
    "                    edgecolors='k', lw=2)\n",
    "        for i in clusters:\n",
    "            if i==-1: # if some cluster number needs to be below the centroid\n",
    "                xytext = (-6, -35)\n",
    "            else:\n",
    "                xytext = (-6, 20)\n",
    "            plt.annotate(\"{}\".format(i+1),\n",
    "                         (CC[i,0], CC[i,1]),\n",
    "                         xytext=xytext, textcoords='offset points',\n",
    "                         fontsize=28, #'xx-large', \n",
    "                         fontweight='bold',\n",
    "                         bbox=dict(facecolor='white', edgecolor='black', lw=2, alpha=0.7,\n",
    "                                   boxstyle='round,pad=0.08'))\n",
    "    if counts is not None:\n",
    "        for i in counts.keys():\n",
    "            if ~np.isnan(i):\n",
    "                i = int(i)\n",
    "                plt.annotate(\"{}: {}\".format(i+1, counts[i]), \n",
    "                             (0.8, 0.3-0.05*i), c = colors[i], #plt.cm.Set1((i+1)/10.),\n",
    "                             fontsize='xx-large', fontweight='bold')  \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize='xx-large', fontweight='bold')\n",
    "    if save_as is not None:\n",
    "        plt.savefig(save_as, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of `x` and `y`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = mpl.patches.Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = mpl.transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_fa = fa.transform(new_kmeans_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(n_factors):\n",
    "    factor = fa.components_[c,:]\n",
    "    absfactor = np.abs(factor)\n",
    "    sorted_indices = np.flip(np.argsort(absfactor))\n",
    "    print('\\n### FA {} ###'.format(c+1))\n",
    "    for i in range(10):\n",
    "        var = df.columns[sorted_indices[i]]\n",
    "        print(\"{:.2f} {} ({})\".format(factor[sorted_indices[i]],\n",
    "                                      var, varsdict[var]['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/faktorit-{}.csv\".format(OUTDIR, todaystr()), 'w') as f:\n",
    "    f.write(\"faktori1,faktori2,faktori3,faktori4,klusteri\\n\")\n",
    "    for i in range(len(X_fa)):\n",
    "        f.write(\"{},{},{},{},{}\\n\".format(X_fa[i,0],X_fa[i,1],\n",
    "                                          X_fa[i,2],X_fa[i,3],\n",
    "                                          new_y[i]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_labels = ['Faktori 1', 'Faktori 2', 'Faktori 3', 'Faktori 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"clusters\": kmeans_labels,\n",
    "        \"cluster_descriptions\": kmeans_descriptions,\n",
    "        \"factors\": fa_labels}\n",
    "with open('{}/descriptions-{}.json'.format(OUTDIR, todaystr()), 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_fa, cc_fa, title=\"FA klusterit\", cov_ell=1.0, coloring=new_y,\n",
    "               save_as=\"{}/fa-12.png\".format(OUTDIR), sizes=POINTSIZE, counts=yc, xylabels=fa_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_fa[:,[2,3]], cc_fa[:,[2,3]], title=\"FA klusterit\", cov_ell=1.0, coloring=new_y,\n",
    "               save_as=\"{}/fa-34.png\".format(OUTDIR), sizes=POINTSIZE, counts=yc, xylabels=[fa_labels[i] for i in [2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "assert n_components>3\n",
    "\n",
    "if LOAD_PCA_MODEL is None:\n",
    "    pca = decomposition.PCA(n_components=n_components, whiten=False)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    _fn = \"pca-{}.joblib\".format(todaystr())\n",
    "    dump(pca, \"{}/{}\".format(OUTDIR, _fn))\n",
    "    print('Wrote', _fn)\n",
    "else:\n",
    "    _fn = \"{}/{}\".format(MODELDIR, LOAD_PCA_MODEL)\n",
    "    assert os.path.isfile(_fn), \"File missing\"\n",
    "    pca = load(_fn)\n",
    "    print('Loaded', LOAD_PCA_MODEL)\n",
    "    X_pca = pca.transform(X)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(np.arange(n_components)+1, \n",
    "        pca.explained_variance_ratio_)\n",
    "plt.title('Explained variance by PCA components')\n",
    "plt.ylabel('explained variance')\n",
    "plt.xlabel('PCA component');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_pca = pca.transform(new_kmeans_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(n_components):\n",
    "    comp = pca.components_[c,:]\n",
    "    abscomp = np.abs(comp)\n",
    "    sorted_indices_pca = np.flip(np.argsort(abscomp))\n",
    "    print('\\n### PCA {} ###'.format(c+1))\n",
    "    for i in range(10):\n",
    "        var = df.columns[sorted_indices_pca[i]]\n",
    "        print(\"{:.2f} {} ({})\".format(comp[sorted_indices_pca[i]],\n",
    "                                      var, varsdict[var]['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/pca-{}.csv\".format(OUTDIR, todaystr()), 'w') as f:\n",
    "    f.write(\"pca1,pca2,pca3,pca4,klusteri\\n\")\n",
    "    for i in range(len(X_pca)):\n",
    "        f.write(\"{},{},{},{},{}\\n\".format(X_pca[i,0],X_pca[i,1],\n",
    "                                          X_pca[i,2],X_pca[i,3],\n",
    "                                          new_y[i]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_labels = ['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = {\"clusters\": kmeans_labels,\n",
    "            \"cluster_descriptions\": kmeans_descriptions,\n",
    "            \"pca_components\": pca_labels}\n",
    "with open('{}/descriptions-pca-{}.json'.format(OUTDIR, todaystr()), 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_pca, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_pca, cc_pca, title=\"PCA klusterit\", cov_ell=1.0, coloring=new_y,\n",
    "               save_as=\"{}/pca-12.png\".format(OUTDIR), sizes=POINTSIZE, counts=yc, xylabels=pca_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_embedding(X_pca, cc_pca, title=None, cov_ell=None, coloring=new_y,\n",
    "               save_as=\"{}/pca-12-new.png\".format(OUTDIR), sizes=2, counts=None, xylabels=pca_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_pca[:,[2,3]], cc_pca[:,[2,3]], title=\"PCA klusterit\", cov_ell=1.0, coloring=new_y,\n",
    "               save_as=\"{}/pca-34.png\".format(OUTDIR), sizes=POINTSIZE, counts=yc, xylabels=[pca_labels[i] for i in [2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if umap is not None:\n",
    "    n_neighbors = 20\n",
    "    min_dist = 0.5 # 0.5 # 0.1\n",
    "    umapmodel = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist)\n",
    "    #noise = np.random.normal(0, .5, X.shape)\n",
    "    X_umap = umapmodel.fit_transform(X)#+noise)\n",
    "    cc_umap = umapmodel.transform(new_kmeans_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if umap is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,3))\n",
    "    ax1.hist(X_umap[:,0],50)\n",
    "    ax1.set_title('x')\n",
    "\n",
    "    ax2.hist(X_umap[:,1], 50)\n",
    "    ax2.set_title('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if umap is not None:\n",
    "    X_umap_filt = X_umap[X_umap[:,0]<0]\n",
    "    y_filt = y[X_umap[:,0]<0]\n",
    "    #imm_filt = imm[X_umap[:,0]<0]\n",
    "    #immsizes_filt = immsizes[X_umap[:,0]<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if umap is not None:\n",
    "    plot_embedding(X_umap, cc_umap,\n",
    "                   \"UMAP projection with n_neighbors=%d, min_dist=%.2f\" % (n_neighbors,\n",
    "                                                                           min_dist),\n",
    "                   save_as=\"{}/umap.png\".format(OUTDIR), sizes=POINTSIZE, coloring=new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
